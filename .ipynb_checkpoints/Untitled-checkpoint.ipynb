{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "web scrapers can access data from databases which expand to millions of pages unlike browser which are generally good at executing js scripts.<br/>\n",
    "A Google search for “cheapest flights to Boston” will result in a slew of advertisements\n",
    "and popular flight search sites. Google only knows what these websites say on their\n",
    "content pages, not the exact results of various queries entered into a flight search\n",
    "application. However, a well-developed web scraper can chart the cost of a flight to\n",
    "Boston over time, across a variety of websites, and tell you the best time to buy your\n",
    "ticket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if it hits you “Isn’t data gathering what APIs are for?” (If you’re unfamiliar\n",
    "with APIs, see Chapter 4.) Well, APIs can be fantastic, if you find one that suits your\n",
    "purposes. They can provide a convenient stream of well-formatted data from one\n",
    "server to another.<br/>\n",
    "• You are gathering data across a collection of sites that do not have a cohesive API.<br/>\n",
    "• The data you want is a fairly small, finite set that the webmaster did not think\n",
    "warranted an API.<br/>\n",
    "• The source does not have the infrastructure or technical ability to create an API.<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i/> A web browser can tell the processor to send some data to the application that handles your wireless (or wired) interface, but many languages have libraries that can do that just as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "html = requests.get(\"http://pythonscraping.com/pages/page1.html\")\n",
    "type(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_html=html.text\n",
    "type(string_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Introduction to BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“Beautiful Soup, so rich and green,<br/>\n",
    "Waiting in a hot tureen!<br/>\n",
    "Who for such dainties would not stoop?<br/>\n",
    "Soup of the evening, beautiful Soup!”<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsObj = BeautifulSoup(string_html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A Useful Page</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1>An Interesting Title</h1>\n",
       "<div>\n",
       "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>An Interesting Title</h1>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsObj.h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we extracted from the page was nested two layers deep\n",
    "into our BeautifulSoup object structure (html → body → h1). However, when we\n",
    "actually fetched it from the object, we called the h1 tag directly:<br/>\n",
    "bsObj.h1<br/>\n",
    "In fact, any of the following function calls would produce the same output:<br/>\n",
    "bsObj.html.body.h1<br/>\n",
    "bsObj.body.h1<br/>\n",
    "bsObj.html.h1<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtually any information can be extracted from any HTML\n",
    "(or XML) file, as long as it has some identifying tag surrounding it, or near it. In\n",
    "chapter 3, we’ll delve more deeply into some more-complex BeautifulSoup function\n",
    "calls, as well as take a look at regular expressions and how they can be used with Beau\n",
    "tifulSoup in order to extract information from websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = requests.get(\"http://www.pythonscraping.com/pages/page1.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, to anticipate the server error or the page not found error we include try and except and othe r conditions to filter the ways the scraping can go wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "#return null, break, or do some other \"Plan B\"\n",
    "else:\n",
    "    #program continues. Note: If you return or break in the\n",
    "    #exception catch, you do not need to use the \"else\" statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if html is None:\n",
    "    print(\"URL is not found\")\n",
    "else:\n",
    "    #program continues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = requests.get(url)\n",
    "        string_html = html.text\n",
    "    except HTTPError as e:             #if page not found for above request\n",
    "                                        #an HTTP error will be returned.\n",
    "        return None\n",
    "    try:\n",
    "        bsObj = BeautifulSoup(string_html,'html.parser')\n",
    "        title = bsObj.body.h1\n",
    "    except AttributeError as e:       #Server not found\n",
    "        return None\n",
    "    return title\n",
    "title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "if title == None:\n",
    "    print(\"Title can't be found\")\n",
    "else:\n",
    "    print(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll also likely want to heavily reuse code. Having generic functions such as getSiteHTML and getTitle (complete with thorough exception handling) makes it easy to quickly—and reliably—scrape the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chap 2\n",
    "### Advanced HTML parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many techniques to chip away the content that doesn’t look like the content that we’re searching for, until we arrive at the information we’re seeking. In this chapter, we’ll take look at parsing complicated HTML pages in order to extract only the information we’re looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need better formatted HTML:<br/>\n",
    "• so what we do is find the print this page link or mobile version link(sometimes by presenting yourself as a mobile device)<br/>\n",
    "• Look for the information hidden in a JavaScript file. Remember, you might need\n",
    "to examine the imported JavaScript files in order to do this. For example, I once\n",
    "collected street addresses (along with latitude and longitude) off a website in a\n",
    "neatly formatted array by looking at the JavaScript for the embedded Google Map\n",
    "that displayed a pinpoint over each address.<br/>\n",
    "• This is more common for page titles, but the information might be available in\n",
    "the URL of the page itself.<br/>\n",
    "• If the information you are looking for is unique to this website for some reason,\n",
    "you’re out of luck. If not, try to think of other sources you could get this informa‐\n",
    "tion from. Is there another website with the same data? Is this website displaying\n",
    "data that it scraped or aggregated from another website?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Especially when faced with buried or poorly formatted data, it’s important not to just start digging. Take a deep breath and think of alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we’ll discuss searching for tags by\n",
    "attributes, working with lists of tags, and parse tree navigation."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CSS styling is boon to scrapers. CSS relies on the differentiation of HTML elements that might otherwise have the exact same markup in order to style them differently.\n",
    "tags might look like:\n",
    "\n",
    "<span class=\"green\"><span>\n",
    "\n",
    "while others look like this:\n",
    "\n",
    "<span class=\"red\"></span>\n",
    "\n",
    "now for scrapers it is really easy to filter tags with only the \"red\" string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = requests.get(\"http://www.pythonscraping.com/pages/warandpeace.html\")\n",
    "string_html=html.text\n",
    "\n",
    "bsObj = BeautifulSoup(string_html,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we used <br/>\n",
    "bsObj.tagName<br/>\n",
    "in order to get the first occurrence of that tag on the page. Now, we’re calling\n",
    "bsObj.findAll(tagName, tagAttributes) in order to get a list of all of the tags on\n",
    "the page, rather than just the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nameList = bsObj.findAll(\"span\", {\"class\":\"green\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"green\">Anna\n",
       " Pavlovna Scherer</span>, <span class=\"green\">Empress Marya\n",
       " Fedorovna</span>, <span class=\"green\">Prince Vasili Kuragin</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">St. Petersburg</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the prince</span>, <span class=\"green\">the prince</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Prince Vasili</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Wintzingerode</span>, <span class=\"green\">King of Prussia</span>, <span class=\"green\">le Vicomte de Mortemart</span>, <span class=\"green\">Montmorencys</span>, <span class=\"green\">Rohans</span>, <span class=\"green\">Abbe Morio</span>, <span class=\"green\">the Emperor</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Prince Vasili</span>, <span class=\"green\">Dowager Empress Marya Fedorovna</span>, <span class=\"green\">the baron</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">Anna Pavlovna's</span>, <span class=\"green\">Her Majesty</span>, <span class=\"green\">Baron\n",
       " Funke</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anna\n",
       " Pavlovna</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anatole</span>, <span class=\"green\">the prince</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anna\n",
       " Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameList #it should list all the proper nouns in the text, in the order they appear in \n",
    "         #War and Peace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### find and findall\n",
    "\n",
    "findAll(tag, attributes, recursive, text, limit, keywords)<br/>\n",
    "find(tag, attributes, recursive, text, keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tag\n",
    "like tag argument (bsObj.body.h1) we can use:<br/>\n",
    "you can pass a string name of a tag\n",
    "or even a Python list of string tag names. For example, the following will return a list\n",
    "of all the header tags in a document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1>War and Peace</h1>, <h2>Chapter 1</h2>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsObj.findAll({'h1','h2','h3','h4','h5','h6'})  ## will find every header from the HTML till \n",
    "                                                ##h6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### attributes\n",
    "The attributes argument takes a Python dictionary of attributes and matches tags\n",
    "that contain any one of those attributes. For example, the following function would\n",
    "return both the green and red span tags in the HTML document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsObj.findAll(\"span\", {\"class\":\"green\", \"class\":\"red\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### recursive\n",
    "\n",
    "The recursive argument is a boolean. How deeply into the document do you want to\n",
    "go? If recursion is set to True , the findAll function looks into children, and child‐\n",
    "ren’s children, for tags that match your parameters. If it is false , it will look only at\n",
    "the top-level tags in your document. By default, findAll works recursively ( recur\n",
    "sive is set to True ); it’s generally a good idea to leave this as is, unless you really know\n",
    "what you need to do and performance is an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### text:\n",
    "The text argument is unusual in that it matches based on the text content of the tags,\n",
    "rather than properties of the tags themselves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "namelist=bsObj.findAll(text='the prince')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(namelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### limit\n",
    "limit is used in findAll, find is equivalent to findAll with limit 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### keyword\n",
    "The keyword argument allows you to select tags that contain a particular attribute.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allText = bsObj.findAll(id=\"text\")\n",
    "print(allText[0].get_text())      # These give you the whole text of the page that you \n",
    "                                  #intended to scrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "everything that can done with keyword can also be done using normal techniques.<br/>\n",
    "above can be accomplished by:<br/>\n",
    "bsObj.findall('',{'id':'text'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other BeautifulSoup Objects:\n",
    "Till now we have seen two types of BS objects:<br/>\n",
    "1) bsObj\n",
    "2) tag objects... (find,findAll)\n",
    "other 2 are:<br/>\n",
    "<p>\n",
    "NavigableString objects\n",
    "Used to represent text within tags, rather than the tags themselves (some func‐\n",
    "tions operate on, and produce, NavigableStrings , rather than tag objects).\n",
    "<p>\n",
    "The Comment object\n",
    "Used to find HTML comments in comment tags, <!--like this one-->\n",
    "These four objects are the only objects you will ever encounter (as of the time of this\n",
    "writing) in the BeautifulSoup library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigating Trees:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "\n",
    "bssObj = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### children and descendants\n",
    "bsObj.body.h1 selects the first h1 tag that is a\n",
    "descendant of the body tag. It will not find tags located outside of the body.<br/>\n",
    "\n",
    "bsObj.div.findAll(\"img\") will find the first div tag in the document,\n",
    "then retrieve a list of all img tags that are descendants of that div tag.<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>If you want to find only descendants that are children, you can use the .children tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for child in bssObj.find(\"table\",{\"id\":\"giftList\"}).children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>This code prints out the list of product rows in the giftList table. If you were to\n",
    "write it using the descendants() function instead of the children() function, about\n",
    "two dozen tags would be found within the table and printed, including img tags, span\n",
    "tags, and individual td tags. It’s definitely important to differentiate between children\n",
    "and descendants!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift1\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift2\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift3\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift4\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift5\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/prashant/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#siblings\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "bsObj = BeautifulSoup(html)\n",
    "for sibling in bsObj.find(\"table\",{\"id\":\"giftList\"}).tr.next_siblings:\n",
    "    print(sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "bsObj= BeautifulSoup(html)\n",
    "images = bsObj.findAll(\"img\", {\"src\":re.compile(\"\\.\\.\\/img\\/gifts/img.*\\.jpg\")}) \n",
    "#This prints out only the relative image paths that start with ../img/gifts/img and end in \n",
    "#.jpg\n",
    "for image in images:\n",
    "    print(image[\"src\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> to get the attributes of the tag objects we use:</i><br/>\n",
    "myTag.attrs<br/>\n",
    "The source location for an\n",
    "image, for example, can be found using the following line:<br/>\n",
    "myImgTag.attrs['src']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every tag object that BeautifulSoup encounters is\n",
    "evaluated in this function, and tags that evaluate to “true” are returned while the rest\n",
    "are discarded.\n",
    "For example, the following retrieves all tags that have exactly two attributes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll(lambda tag: len(tag.attrs) == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
